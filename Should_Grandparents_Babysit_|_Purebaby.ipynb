{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMXcmDGlR+tO++8nMZX8GPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dani-studiohawk/Grandparentsbabysitting/blob/main/Should_Grandparents_Babysit_%7C_Purebaby.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iWlw5nxtiLwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7dxAmrh3Be",
        "outputId": "1028c779-edfc-461f-e335-675df7dc96a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded: True\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve colab secret\n",
        "api_key = userdata.get('DaniKey')\n",
        "\n",
        "# create client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# not printing the actual key\n",
        "print(\"API key loaded:\", api_key is not None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relevance"
      ],
      "metadata": {
        "id": "UWZYpM7EiR-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So my first step was for GPT to go in and determine whether the comment was relevant to the direct conversation of 'Should grandparents be paid to babysit'. This allows us to filter out all of the noise, ie jokes, memes and deleted messages from the offset."
      ],
      "metadata": {
        "id": "L07-jUqlPy33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"reddit_thread_with_relevance.csv\", dtype=str)\n",
        "\n",
        "# rerun and identify eror rows\n",
        "error_mask = df[\"relevance\"] == \"error\"\n",
        "error_rows = df[error_mask]\n",
        "\n",
        "print(f\"Found {len(error_rows)} rows with errors. Reprocessing now.\")\n",
        "\n",
        "\n",
        "TASK_PROMPT = (\n",
        "    \"You are classifying whether a Reddit comment is relevant to the question: \"\n",
        "    \"'Should grandparents be paid for babysitting grandchildren'.\\n\\n\"\n",
        "    \"RELEVANT means:\\n\"\n",
        "    \"• The comment expresses an opinion about paying or not paying grandparents.\\n\"\n",
        "    \"• The comment discusses babysitting, childcare, compensation, fairness, or responsibility.\\n\"\n",
        "    \"• The comment provides anecdotes, arguments, or examples about the issue.\\n\"\n",
        "    \"• The comment responds directly to another point about paying grandparents.\\n\\n\"\n",
        "    \"IRRELEVANT means:\\n\"\n",
        "    \"• The comment does not address payment, childcare, or babysitting.\\n\"\n",
        "    \"• The comment is off-topic, a joke, a meme, a tag, or noise.\\n\"\n",
        "    \"• The comment only discusses grandparents or children in general, not payment.\\n\"\n",
        "    \"• The comment is meta-discussion about Reddit or the thread.\\n\\n\"\n",
        "    \"OUTPUT FORMAT:\\n\"\n",
        "    \"You must respond in exactly two lines:\\n\"\n",
        "    \"relevance: relevant or irrelevant\\n\"\n",
        "    \"reason: a short explanation\\n\\n\"\n",
        "    \"Comment: <<<COMMENT>>>\"\n",
        ")\n",
        "\n",
        "\n",
        "def clean_comment(text):\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\x00\", \"\")\n",
        "    return text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\").strip()\n",
        "\n",
        "\n",
        "def parse_two_line_output(raw):\n",
        "    relevance = \"error\"\n",
        "    reason = raw.strip()\n",
        "\n",
        "    lines = raw.splitlines()\n",
        "    for line in lines:\n",
        "        lower = line.lower().strip()\n",
        "\n",
        "        if lower.startswith(\"relevance:\"):\n",
        "            value = lower.replace(\"relevance:\", \"\").strip()\n",
        "            if value in [\"relevant\", \"irrelevant\"]:\n",
        "                relevance = value\n",
        "\n",
        "        elif lower.startswith(\"reason:\"):\n",
        "            reason = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "    return relevance, reason\n",
        "\n",
        "\n",
        "def classify_comment(comment, retries=1):\n",
        "    comment_clean = clean_comment(comment)\n",
        "    prompt = TASK_PROMPT.replace(\"<<<COMMENT>>>\", comment_clean)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Follow the two-line output format strictly.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_completion_tokens=300\n",
        "        )\n",
        "\n",
        "        raw = response.choices[0].message.content\n",
        "        relevance, reason = parse_two_line_output(raw)\n",
        "\n",
        "        # Retry if parsing failed\n",
        "        if relevance == \"error\" and retries > 0:\n",
        "            return classify_comment(comment, retries=retries - 1)\n",
        "\n",
        "        return relevance, reason\n",
        "\n",
        "    except Exception as e:\n",
        "        if retries > 0:\n",
        "            return classify_comment(comment, retries=retries - 1)\n",
        "        return \"error\", str(e)\n",
        "\n",
        "\n",
        "\n",
        "for idx, row in error_rows.iterrows():\n",
        "    comment = row[\"body\"]\n",
        "\n",
        "    print(f\"Processing row {idx}...\", end=\" \")\n",
        "\n",
        "    relevance, reason = classify_comment(comment)\n",
        "\n",
        "    df.at[idx, \"relevance\"] = relevance\n",
        "    df.at[idx, \"reason\"] = reason\n",
        "\n",
        "    print(f\"→ {relevance}\")\n",
        "\n",
        "\n",
        "\n",
        "df.to_csv(\"reddit_thread_with_relevance_fixed.csv\", index=False)\n",
        "print(\"Done. Saved as reddit_thread_with_relevance_fixed.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NAcG69GIiaOz",
        "outputId": "75d1395f-5f78-4209-bbe0-19edeb1d8b34"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 136 rows with errors. Reprocessing now.\n",
            "Processing row 0... → relevant\n",
            "Processing row 1... → relevant\n",
            "Processing row 2... → relevant\n",
            "Processing row 6... → irrelevant\n",
            "Processing row 7... → irrelevant\n",
            "Processing row 10... → relevant\n",
            "Processing row 11... → relevant\n",
            "Processing row 13... → relevant\n",
            "Processing row 14... → relevant\n",
            "Processing row 15... → relevant\n",
            "Processing row 16... → relevant\n",
            "Processing row 18... → irrelevant\n",
            "Processing row 20... → irrelevant\n",
            "Processing row 22... → relevant\n",
            "Processing row 28... → relevant\n",
            "Processing row 30... → relevant\n",
            "Processing row 35... → relevant\n",
            "Processing row 38... → relevant\n",
            "Processing row 41... → relevant\n",
            "Processing row 42... → irrelevant\n",
            "Processing row 43... → irrelevant\n",
            "Processing row 50... → relevant\n",
            "Processing row 53... → relevant\n",
            "Processing row 55... → irrelevant\n",
            "Processing row 56... → relevant\n",
            "Processing row 57... → relevant\n",
            "Processing row 58... → irrelevant\n",
            "Processing row 61... → irrelevant\n",
            "Processing row 64... → irrelevant\n",
            "Processing row 65... → relevant\n",
            "Processing row 68... → relevant\n",
            "Processing row 69... → relevant\n",
            "Processing row 73... → relevant\n",
            "Processing row 74... → relevant\n",
            "Processing row 76... → relevant\n",
            "Processing row 80... → relevant\n",
            "Processing row 85... → relevant\n",
            "Processing row 91... → relevant\n",
            "Processing row 92... → relevant\n",
            "Processing row 102... → relevant\n",
            "Processing row 104... → relevant\n",
            "Processing row 107... → relevant\n",
            "Processing row 108... → relevant\n",
            "Processing row 109... → relevant\n",
            "Processing row 110... → relevant\n",
            "Processing row 113... → relevant\n",
            "Processing row 114... → relevant\n",
            "Processing row 115... → relevant\n",
            "Processing row 116... → relevant\n",
            "Processing row 124... → relevant\n",
            "Processing row 126... → relevant\n",
            "Processing row 128... → relevant\n",
            "Processing row 129... → irrelevant\n",
            "Processing row 130... → relevant\n",
            "Processing row 132... → relevant\n",
            "Processing row 133... → relevant\n",
            "Processing row 135... → relevant\n",
            "Processing row 139... → relevant\n",
            "Processing row 141... → relevant\n",
            "Processing row 146... → relevant\n",
            "Processing row 147... → irrelevant\n",
            "Processing row 148... → relevant\n",
            "Processing row 151... → relevant\n",
            "Processing row 152... → irrelevant\n",
            "Processing row 154... → relevant\n",
            "Processing row 156... → relevant\n",
            "Processing row 158... → relevant\n",
            "Processing row 161... → relevant\n",
            "Processing row 172... → relevant\n",
            "Processing row 173... → relevant\n",
            "Processing row 175... → irrelevant\n",
            "Processing row 179... → relevant\n",
            "Processing row 181... → relevant\n",
            "Processing row 191... → relevant\n",
            "Processing row 192... → irrelevant\n",
            "Processing row 194... → relevant\n",
            "Processing row 201... → relevant\n",
            "Processing row 209... → relevant\n",
            "Processing row 213... → irrelevant\n",
            "Processing row 216... → irrelevant\n",
            "Processing row 217... → relevant\n",
            "Processing row 220... → relevant\n",
            "Processing row 222... → irrelevant\n",
            "Processing row 224... → relevant\n",
            "Processing row 226... → relevant\n",
            "Processing row 227... → relevant\n",
            "Processing row 229... → irrelevant\n",
            "Processing row 230... → relevant\n",
            "Processing row 234... → relevant\n",
            "Processing row 237... → irrelevant\n",
            "Processing row 238... → irrelevant\n",
            "Processing row 239... → relevant\n",
            "Processing row 242... → relevant\n",
            "Processing row 243... → irrelevant\n",
            "Processing row 247... → irrelevant\n",
            "Processing row 256... → relevant\n",
            "Processing row 262... → irrelevant\n",
            "Processing row 267... → relevant\n",
            "Processing row 268... → relevant\n",
            "Processing row 269... → irrelevant\n",
            "Processing row 270... → irrelevant\n",
            "Processing row 273... → irrelevant\n",
            "Processing row 277... → relevant\n",
            "Processing row 282... → relevant\n",
            "Processing row 285... → irrelevant\n",
            "Processing row 286... → relevant\n",
            "Processing row 288... → relevant\n",
            "Processing row 290... → relevant\n",
            "Processing row 293... → irrelevant\n",
            "Processing row 294... → irrelevant\n",
            "Processing row 295... → irrelevant\n",
            "Processing row 297... → relevant\n",
            "Processing row 298... → irrelevant\n",
            "Processing row 302... → relevant\n",
            "Processing row 310... → irrelevant\n",
            "Processing row 311... → irrelevant\n",
            "Processing row 320... → irrelevant\n",
            "Processing row 322... → relevant\n",
            "Processing row 323... → relevant\n",
            "Processing row 326... → irrelevant\n",
            "Processing row 327... → irrelevant\n",
            "Processing row 328... → relevant\n",
            "Processing row 330... → relevant\n",
            "Processing row 333... → irrelevant\n",
            "Processing row 334... → irrelevant\n",
            "Processing row 336... → relevant\n",
            "Processing row 338... → irrelevant\n",
            "Processing row 339... → irrelevant\n",
            "Processing row 340... → irrelevant\n",
            "Processing row 342... → irrelevant\n",
            "Processing row 345... → irrelevant\n",
            "Processing row 347... → irrelevant\n",
            "Processing row 348... → relevant\n",
            "Processing row 349... → irrelevant\n",
            "Processing row 351... → irrelevant\n",
            "Processing row 353... → relevant\n",
            "Done. Saved as reddit_thread_with_relevance_fixed.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This leaves us with 266 relevant comments."
      ],
      "metadata": {
        "id": "jThuoxXRrP4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For or Against"
      ],
      "metadata": {
        "id": "y_I-ealuO7H-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because Clea is primarily interested in percentages and statistical analysis, my next step was to breakdown the dataset into clearly labelled For, Against or Neutral. I had GPT output the reason it made that determination in order to help spot check that the output was correct.\n",
        "\n",
        "This step mainly allows us to breakdown the data in a way that can be quoted cleanly:\n",
        "\n",
        "What proportion support paying?\n",
        "\n",
        "What proportion opposes?\n",
        "\n",
        "How many sit on the fence?"
      ],
      "metadata": {
        "id": "nxCWJn8dQHYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"reddit_thread_with_relevance_fixed.csv\", dtype=str)\n",
        "\n",
        "relevant_df = df[df[\"relevance\"] == \"relevant\"]\n",
        "print(f\"Found {len(relevant_df)} relevant comments. Classifying positions now.\")\n",
        "\n",
        "POSITION_PROMPT = (\n",
        "    \"Classify the stance of the Reddit comment on whether grandparents \"\n",
        "    \"should be paid for babysitting grandchildren.\\n\\n\"\n",
        "    \"FOR means:\\n\"\n",
        "    \"The comment supports paying grandparents.\\n\"\n",
        "    \"It argues in favour of compensation, fairness, or respecting their time.\\n\\n\"\n",
        "    \"AGAINST means:\\n\"\n",
        "    \"The comment argues grandparents should not be paid.\\n\"\n",
        "    \"It frames babysitting as a family duty or something that should not involve money.\\n\\n\"\n",
        "    \"NEUTRAL means:\\n\"\n",
        "    \"The comment discusses the topic but does not clearly choose a side.\\n\"\n",
        "    \"The stance is mixed, unclear, or only descriptive.\\n\\n\"\n",
        "    \"OUTPUT FORMAT (exactly two lines):\\n\"\n",
        "    \"position: for or against or neutral\\n\"\n",
        "    \"reason: short explanation\\n\\n\"\n",
        "    \"Comment: <<<COMMENT>>>\"\n",
        ")\n",
        "\n",
        "\n",
        "def clean_comment(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\x00\", \"\")\n",
        "    return text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\").strip()\n",
        "\n",
        "def parse_two_line_output(raw):\n",
        "    position = \"error\"\n",
        "    reason = raw.strip()\n",
        "\n",
        "    lines = raw.splitlines()\n",
        "    for line in lines:\n",
        "        lower = line.lower().strip()\n",
        "        if lower.startswith(\"position:\"):\n",
        "            val = lower.replace(\"position:\", \"\").strip()\n",
        "            if val in [\"for\", \"against\", \"neutral\"]:\n",
        "                position = val\n",
        "        elif lower.startswith(\"reason:\"):\n",
        "            reason = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "    return position, reason\n",
        "\n",
        "def classify_position(comment, retries=1):\n",
        "    comment_clean = clean_comment(comment)\n",
        "    prompt = POSITION_PROMPT.replace(\"<<<COMMENT>>>\", comment_clean)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Respond strictly in two lines.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_completion_tokens=200\n",
        "        )\n",
        "\n",
        "        raw = response.choices[0].message.content\n",
        "        position, reason = parse_two_line_output(raw)\n",
        "\n",
        "        if position == \"error\" and retries > 0:\n",
        "            return classify_position(comment, retries=retries - 1)\n",
        "\n",
        "        return position, reason\n",
        "\n",
        "    except Exception as e:\n",
        "        if retries > 0:\n",
        "            return classify_position(comment, retries=retries - 1)\n",
        "        return \"error\", str(e)\n",
        "\n",
        "\n",
        "df[\"position\"] = None\n",
        "df[\"position_reason\"] = None\n",
        "\n",
        "for idx, row in relevant_df.iterrows():\n",
        "    comment = row[\"body\"]\n",
        "    print(f\"Classifying row {idx}...\", end=\" \")\n",
        "\n",
        "    position, reason = classify_position(comment)\n",
        "\n",
        "    df.at[idx, \"position\"] = position\n",
        "    df.at[idx, \"position_reason\"] = reason\n",
        "\n",
        "    print(f\"→ {position}\")\n",
        "\n",
        "\n",
        "df.to_csv(\"reddit_thread_with_positions.csv\", index=False)\n",
        "print(\"Done. Saved as reddit_thread_with_positions.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "VuXHBXyykNVK",
        "outputId": "440c506c-b469-482c-9f7c-a520fde2d1ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 263 relevant comments. Classifying positions now.\n",
            "Classifying row 0... → neutral\n",
            "Classifying row 1... → against\n",
            "Classifying row 2... → for\n",
            "Classifying row 4... → against\n",
            "Classifying row 9... → neutral\n",
            "Classifying row 10... → neutral\n",
            "Classifying row 11... → neutral\n",
            "Classifying row 12... → against\n",
            "Classifying row 13... → against\n",
            "Classifying row 14... → neutral\n",
            "Classifying row 15... → against\n",
            "Classifying row 16... → against\n",
            "Classifying row 17... → against\n",
            "Classifying row 19... → neutral\n",
            "Classifying row 21... → for\n",
            "Classifying row 22... → neutral\n",
            "Classifying row 24... → neutral\n",
            "Classifying row 25... → neutral\n",
            "Classifying row 26... → against\n",
            "Classifying row 27... → neutral\n",
            "Classifying row 28... → for\n",
            "Classifying row 29... → against\n",
            "Classifying row 30... → against\n",
            "Classifying row 31... → against\n",
            "Classifying row 32... → against\n",
            "Classifying row 33... → neutral\n",
            "Classifying row 34... → against\n",
            "Classifying row 35... → against\n",
            "Classifying row 36... → neutral\n",
            "Classifying row 37... → neutral\n",
            "Classifying row 38... → against\n",
            "Classifying row 39... → against\n",
            "Classifying row 40... → neutral\n",
            "Classifying row 41... → against\n",
            "Classifying row 45... → for\n",
            "Classifying row 46... → neutral\n",
            "Classifying row 47... → against\n",
            "Classifying row 48... → against\n",
            "Classifying row 49... → for\n",
            "Classifying row 50... → neutral\n",
            "Classifying row 51... → neutral\n",
            "Classifying row 52... → against\n",
            "Classifying row 53... → against\n",
            "Classifying row 54... → neutral\n",
            "Classifying row 56... → against\n",
            "Classifying row 57... → against\n",
            "Classifying row 59... → against\n",
            "Classifying row 60... → neutral\n",
            "Classifying row 62... → neutral\n",
            "Classifying row 63... → against\n",
            "Classifying row 65... → against\n",
            "Classifying row 66... → against\n",
            "Classifying row 67... → against\n",
            "Classifying row 68... → against\n",
            "Classifying row 69... → neutral\n",
            "Classifying row 70... → against\n",
            "Classifying row 72... → against\n",
            "Classifying row 73... → against\n",
            "Classifying row 74... → neutral\n",
            "Classifying row 75... → against\n",
            "Classifying row 76... → for\n",
            "Classifying row 77... → for\n",
            "Classifying row 78... → neutral\n",
            "Classifying row 79... → against\n",
            "Classifying row 80... → for\n",
            "Classifying row 81... → against\n",
            "Classifying row 82... → neutral\n",
            "Classifying row 83... → against\n",
            "Classifying row 84... → against\n",
            "Classifying row 85... → neutral\n",
            "Classifying row 86... → against\n",
            "Classifying row 87... → neutral\n",
            "Classifying row 88... → neutral\n",
            "Classifying row 89... → against\n",
            "Classifying row 90... → neutral\n",
            "Classifying row 91... → neutral\n",
            "Classifying row 92... → for\n",
            "Classifying row 93... → against\n",
            "Classifying row 94... → against\n",
            "Classifying row 95... → against\n",
            "Classifying row 96... → neutral\n",
            "Classifying row 97... → against\n",
            "Classifying row 98... → against\n",
            "Classifying row 99... → neutral\n",
            "Classifying row 101... → against\n",
            "Classifying row 102... → against\n",
            "Classifying row 103... → against\n",
            "Classifying row 104... → against\n",
            "Classifying row 105... → for\n",
            "Classifying row 106... → neutral\n",
            "Classifying row 107... → neutral\n",
            "Classifying row 108... → against\n",
            "Classifying row 109... → neutral\n",
            "Classifying row 110... → for\n",
            "Classifying row 111... → neutral\n",
            "Classifying row 112... → for\n",
            "Classifying row 113... → neutral\n",
            "Classifying row 114... → neutral\n",
            "Classifying row 115... → neutral\n",
            "Classifying row 116... → neutral\n",
            "Classifying row 117... → neutral\n",
            "Classifying row 118... → against\n",
            "Classifying row 119... → neutral\n",
            "Classifying row 120... → neutral\n",
            "Classifying row 121... → neutral\n",
            "Classifying row 122... → neutral\n",
            "Classifying row 123... → against\n",
            "Classifying row 124... → neutral\n",
            "Classifying row 125... → neutral\n",
            "Classifying row 126... → for\n",
            "Classifying row 127... → neutral\n",
            "Classifying row 128... → neutral\n",
            "Classifying row 130... → against\n",
            "Classifying row 131... → neutral\n",
            "Classifying row 132... → neutral\n",
            "Classifying row 133... → against\n",
            "Classifying row 134... → against\n",
            "Classifying row 135... → neutral\n",
            "Classifying row 136... "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1150579402.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Classifying row {idx}...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"position\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1150579402.py\u001b[0m in \u001b[0;36mclassify_position\u001b[0;34m(comment, retries)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4.1-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1188\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    983\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us\n",
        "\n",
        "For: 42\n",
        "\n",
        "Against: 111\n",
        "\n",
        "Neutral: 113"
      ],
      "metadata": {
        "id": "bnPj6otwsp_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Reasons"
      ],
      "metadata": {
        "id": "y8jQMAQHtgft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage, when determining reasons, I considered what I'd imagine to be the most likley reasons having looked at the dataset and read a lot of the comments. I used Chatgpt browser to help me come up with clear categories.\n",
        "\n",
        "I then got ChatGPT to assign each FOR comment to one of the 5 categories I came up with. This allows us to look at this data statistically."
      ],
      "metadata": {
        "id": "Obb5NTPHQ1bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"reddit_thread_with_positions.csv\", dtype=str)\n",
        "\n",
        "# Filter to only \"for\" rows\n",
        "for_rows = df[df[\"position\"] == \"for\"]\n",
        "print(f\"Found {len(for_rows)} rows needing reason categorisation.\")\n",
        "\n",
        "\n",
        "CATEGORIES_TEXT = \"\"\"\n",
        "Classify the reason why the commenter supports paying grandparents for babysitting.\n",
        "Choose exactly one of the following categories:\n",
        "\n",
        "1. Compensation for labour and effort\n",
        "2. Preventing financial harm or lost income\n",
        "3. Fairness and avoiding exploitation\n",
        "4. Covering expenses and out of pocket costs\n",
        "5. Systemic or policy reasons\n",
        "\n",
        "Definitions:\n",
        "1. Compensation for labour and effort = Emphasises childcare being tiring, hard work, or equivalent to a job.\n",
        "2. Preventing financial harm or lost income = Mentions rent, lost work hours, fixed income, or financial strain.\n",
        "3. Fairness and avoiding exploitation = Focuses on fairness, being used, guilt, respect, or boundary violations.\n",
        "4. Covering expenses and out of pocket costs = Mentions petrol, food, outings, activities, supplies.\n",
        "5. Systemic or policy reasons = Discusses government subsidies, pension supplements, or pressure on childcare systems.\n",
        "\n",
        "OUTPUT FORMAT (exactly two lines):\n",
        "category: one of the five categories above\n",
        "reason: very short explanation\n",
        "\n",
        "Comment: <<<COMMENT>>>\n",
        "\"\"\"\n",
        "\n",
        "def clean_comment(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\x00\", \"\")\n",
        "    return text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\").strip()\n",
        "\n",
        "\n",
        "def parse_two_line_cat(raw):\n",
        "    category = \"error\"\n",
        "    reason = raw.strip()\n",
        "\n",
        "    for line in raw.splitlines():\n",
        "        lower = line.lower().strip()\n",
        "        if lower.startswith(\"category:\"):\n",
        "            category = line.split(\":\", 1)[1].strip()\n",
        "        elif lower.startswith(\"reason:\"):\n",
        "            reason = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "    return category, reason\n",
        "\n",
        "\n",
        "def classify_for_reason(comment, retries=1):\n",
        "    text = clean_comment(comment)\n",
        "    prompt = CATEGORIES_TEXT.replace(\"<<<COMMENT>>>\", text)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Respond strictly in two lines.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_completion_tokens=200\n",
        "        )\n",
        "        raw = response.choices[0].message.content\n",
        "        category, reason = parse_two_line_cat(raw)\n",
        "\n",
        "        if category == \"error\" and retries > 0:\n",
        "            return classify_for_reason(comment, retries - 1)\n",
        "\n",
        "        return category, reason\n",
        "\n",
        "    except Exception as e:\n",
        "        if retries > 0:\n",
        "            return classify_for_reason(comment, retries - 1)\n",
        "        return \"error\", str(e)\n",
        "\n",
        "\n",
        "df[\"for_reason_category\"] = None\n",
        "df[\"for_reason_explanation\"] = None\n",
        "\n",
        "for idx, row in for_rows.iterrows():\n",
        "    comment = row[\"body\"]\n",
        "    print(f\"Categorising row {idx}...\", end=\" \")\n",
        "\n",
        "    category, explanation = classify_for_reason(comment)\n",
        "\n",
        "    df.at[idx, \"for_reason_category\"] = category\n",
        "    df.at[idx, \"for_reason_explanation\"] = explanation\n",
        "\n",
        "    print(f\"→ {category}\")\n",
        "\n",
        "df.to_csv(\"reddit_thread_with_for_categories.csv\", index=False)\n",
        "print(\"Done. Saved as reddit_thread_with_for_categories.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twygHQfItjHo",
        "outputId": "6c97b96f-498c-43cd-afd8-7459acf40d30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 42 rows needing reason categorisation.\n",
            "Categorising row 2... → Compensation for labour and effort\n",
            "Categorising row 19... → Preventing financial harm or lost income\n",
            "Categorising row 21... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 28... → 1. Compensation for labour and effort\n",
            "Categorising row 45... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 49... → 5. Systemic or policy reasons\n",
            "Categorising row 74... → 4. Covering expenses and out of pocket costs\n",
            "Categorising row 76... → 2. Preventing financial harm or lost income\n",
            "Categorising row 80... → 5. Systemic or policy reasons\n",
            "Categorising row 92... → 5. Systemic or policy reasons\n",
            "Categorising row 110... → 4. Covering expenses and out of pocket costs\n",
            "Categorising row 126... → 2. Preventing financial harm or lost income\n",
            "Categorising row 142... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 150... → Compensation for labour and effort\n",
            "Categorising row 155... → 1. Compensation for labour and effort\n",
            "Categorising row 158... → 1. Compensation for labour and effort\n",
            "Categorising row 165... → 2. Preventing financial harm or lost income\n",
            "Categorising row 178... → 5. Systemic or policy reasons\n",
            "Categorising row 184... → 1. Compensation for labour and effort\n",
            "Categorising row 191... → 5. Systemic or policy reasons\n",
            "Categorising row 194... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 201... → Preventing financial harm or lost income\n",
            "Categorising row 202... → Compensation for labour and effort\n",
            "Categorising row 209... → Compensation for labour and effort\n",
            "Categorising row 217... → 2. Preventing financial harm or lost income\n",
            "Categorising row 218... → Preventing financial harm or lost income\n",
            "Categorising row 224... → 1. Compensation for labour and effort\n",
            "Categorising row 226... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 240... → 2. Preventing financial harm or lost income\n",
            "Categorising row 253... → 4. Covering expenses and out of pocket costs\n",
            "Categorising row 254... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 256... → Compensation for labour and effort\n",
            "Categorising row 257... → 4. Covering expenses and out of pocket costs\n",
            "Categorising row 260... → 3. Fairness and avoiding exploitation\n",
            "Categorising row 265... → Fairness and avoiding exploitation\n",
            "Categorising row 275... → 1. Compensation for labour and effort\n",
            "Categorising row 281... → Compensation for labour and effort\n",
            "Categorising row 282... → 4. Covering expenses and out of pocket costs\n",
            "Categorising row 285... → Compensation for labour and effort\n",
            "Categorising row 328... → 1. Compensation for labour and effort\n",
            "Categorising row 331... → 4. Covering expenses and out of pocket costs\n",
            "Categorising row 332... → 3. Fairness and avoiding exploitation\n",
            "Done. Saved as reddit_thread_with_for_categories.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Against Section"
      ],
      "metadata": {
        "id": "a1cOFL26uNj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I followed the same steps that I outlined in FOR Reasons."
      ],
      "metadata": {
        "id": "d1-D0W2lRZ1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"reddit_thread_with_positions.csv\", dtype=str)\n",
        "\n",
        "# Filter only \"against\" rows\n",
        "against_rows = df[df[\"position\"] == \"against\"]\n",
        "print(f\"Found {len(against_rows)} rows needing AGAINST reason categorisation.\")\n",
        "\n",
        "\n",
        "CATEGORIES_TEXT_AGAINST = \"\"\"\n",
        "Classify the reason why the commenter opposes paying grandparents for babysitting.\n",
        "Choose exactly one of the following categories:\n",
        "\n",
        "1. Family duty and relationship building\n",
        "2. Anti-transactional or moral objections\n",
        "3. Prefer professional childcare instead\n",
        "4. Cultural or generational norms against payment\n",
        "5. Payment is impractical, unnecessary, or creates complications\n",
        "\n",
        "Definitions:\n",
        "1. Family duty and relationship building = Emphasises love, bonding, creating memories, or that family helps family.\n",
        "2. Anti-transactional = Says paying is transactional, morally wrong, erodes family values, or harms relationships.\n",
        "3. Prefer professional childcare = Argues that if money is involved it should go to trained childcare workers.\n",
        "4. Cultural or generational norms = Mentions cultural attitudes, upbringing, reciprocity, grandparents refusing payment.\n",
        "5. Impractical or unnecessary = Points out pension/tax issues, bureaucracy, tension, refusal to accept money, or that gifts/not money are appropriate.\n",
        "\n",
        "OUTPUT FORMAT (exactly two lines):\n",
        "category: one of the five categories above\n",
        "reason: very short explanation\n",
        "\n",
        "Comment: <<<COMMENT>>>\n",
        "\"\"\"\n",
        "\n",
        "def clean_comment(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\x00\", \"\")\n",
        "    return text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\").strip()\n",
        "\n",
        "def parse_two_line_cat(raw):\n",
        "    category = \"error\"\n",
        "    reason = raw.strip()\n",
        "\n",
        "    for line in raw.splitlines():\n",
        "        lower = line.lower().strip()\n",
        "        if lower.startswith(\"category:\"):\n",
        "            category = line.split(\":\", 1)[1].strip()\n",
        "        elif lower.startswith(\"reason:\"):\n",
        "            reason = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "    return category, reason\n",
        "\n",
        "def classify_against_reason(comment, retries=1):\n",
        "    text = clean_comment(comment)\n",
        "    prompt = CATEGORIES_TEXT_AGAINST.replace(\"<<<COMMENT>>>\", text)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Respond strictly in two lines.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_completion_tokens=200\n",
        "        )\n",
        "        raw = response.choices[0].message.content\n",
        "        category, reason = parse_two_line_cat(raw)\n",
        "\n",
        "        if category == \"error\" and retries > 0:\n",
        "            return classify_against_reason(comment, retries - 1)\n",
        "\n",
        "        return category, reason\n",
        "\n",
        "    except Exception as e:\n",
        "        if retries > 0:\n",
        "            return classify_against_reason(comment, retries - 1)\n",
        "        return \"error\", str(e)\n",
        "\n",
        "\n",
        "df[\"against_reason_category\"] = None\n",
        "df[\"against_reason_explanation\"] = None\n",
        "\n",
        "for idx, row in against_rows.iterrows():\n",
        "    comment = row[\"body\"]\n",
        "    print(f\"Categorising row {idx}...\", end=\" \")\n",
        "\n",
        "    category, explanation = classify_against_reason(comment)\n",
        "\n",
        "    df.at[idx, \"against_reason_category\"] = category\n",
        "    df.at[idx, \"against_reason_explanation\"] = explanation\n",
        "\n",
        "    print(f\"→ {category}\")\n",
        "\n",
        "\n",
        "df.to_csv(\"reddit_thread_with_all_reason_categories.csv\", index=False)\n",
        "print(\"Done. Saved as reddit_thread_with_all_reason_categories.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_xk9QsHfuQ0z",
        "outputId": "f2b6e76b-22b2-4dca-a734-39dd66881532"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 111 rows needing AGAINST reason categorisation.\n",
            "Categorising row 1... → 1. Family duty and relationship building\n",
            "Categorising row 4... → 1. Family duty and relationship building\n",
            "Categorising row 12... → 4. Cultural or generational norms\n",
            "Categorising row 13... → 4. Cultural or generational norms\n",
            "Categorising row 15... → 3. Prefer professional childcare instead\n",
            "Categorising row 16... → 3. Prefer professional childcare instead\n",
            "Categorising row 17... → 2. Anti-transactional or moral objections\n",
            "Categorising row 25... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 26... → 1. Family duty and relationship building\n",
            "Categorising row 29... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 30... → 4. Cultural or generational norms\n",
            "Categorising row 31... → 1. Family duty and relationship building\n",
            "Categorising row 32... → 4. Cultural or generational norms\n",
            "Categorising row 34... → 1. Family duty and relationship building\n",
            "Categorising row 35... → 4. Cultural or generational norms\n",
            "Categorising row 38... → 3. Prefer professional childcare instead\n",
            "Categorising row 39... → 2. Anti-transactional or moral objections\n",
            "Categorising row 41... → 4. Cultural or generational norms\n",
            "Categorising row 47... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 48... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 52... → 1. Family duty and relationship building\n",
            "Categorising row 53... → 1. Family duty and relationship building\n",
            "Categorising row 56... → 1. Family duty and relationship building\n",
            "Categorising row 57... → 4. Cultural or generational norms\n",
            "Categorising row 58... → 2. Anti-transactional or moral objections\n",
            "Categorising row 59... → 4. Cultural or generational norms\n",
            "Categorising row 62... → 1. Family duty and relationship building\n",
            "Categorising row 63... → 4. Cultural or generational norms\n",
            "Categorising row 65... → 4. Cultural or generational norms\n",
            "Categorising row 66... → 1. Family duty and relationship building\n",
            "Categorising row 67... → 2. Anti-transactional or moral objections\n",
            "Categorising row 68... → 2. Anti-transactional or moral objections\n",
            "Categorising row 70... → 3. Prefer professional childcare instead\n",
            "Categorising row 72... → 2. Anti-transactional or moral objections\n",
            "Categorising row 73... → 2. Anti-transactional or moral objections\n",
            "Categorising row 75... → 1. Family duty and relationship building\n",
            "Categorising row 79... → 1. Family duty and relationship building\n",
            "Categorising row 81... → 4. Cultural or generational norms\n",
            "Categorising row 82... → 1. Family duty and relationship building\n",
            "Categorising row 83... → 1. Family duty and relationship building\n",
            "Categorising row 84... → 1. Family duty and relationship building\n",
            "Categorising row 86... → 4. Cultural or generational norms\n",
            "Categorising row 89... → 1. Family duty and relationship building\n",
            "Categorising row 93... → 1. Family duty and relationship building\n",
            "Categorising row 94... → 2. Anti-transactional or moral objections\n",
            "Categorising row 95... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 97... → 1. Family duty and relationship building\n",
            "Categorising row 98... → 4. Cultural or generational norms against payment\n",
            "Categorising row 101... → 2. Anti-transactional or moral objections\n",
            "Categorising row 102... → 1. Family duty and relationship building\n",
            "Categorising row 103... → 4. Cultural or generational norms\n",
            "Categorising row 108... → 4. Cultural or generational norms\n",
            "Categorising row 118... → 1. Family duty and relationship building\n",
            "Categorising row 123... → 1. Family duty and relationship building\n",
            "Categorising row 130... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 133... → 4. Cultural or generational norms\n",
            "Categorising row 134... → 1. Family duty and relationship building\n",
            "Categorising row 136... → 1. Family duty and relationship building\n",
            "Categorising row 140... → Family duty and relationship building\n",
            "Categorising row 141... → 4. Cultural or generational norms\n",
            "Categorising row 143... → 4. Cultural or generational norms\n",
            "Categorising row 144... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 156... → 3. Prefer professional childcare instead\n",
            "Categorising row 157... → 4. Cultural or generational norms\n",
            "Categorising row 166... → 2. Anti-transactional or moral objections\n",
            "Categorising row 169... → 2. Anti-transactional or moral objections\n",
            "Categorising row 170... → 2. Anti-transactional or moral objections\n",
            "Categorising row 171... → 1. Family duty and relationship building\n",
            "Categorising row 172... → 4. Cultural or generational norms\n",
            "Categorising row 173... → 2. Anti-transactional or moral objections\n",
            "Categorising row 174... → 4. Cultural or generational norms\n",
            "Categorising row 177... → 1. Family duty and relationship building\n",
            "Categorising row 180... → 1. Family duty and relationship building\n",
            "Categorising row 181... → 1. Family duty and relationship building\n",
            "Categorising row 185... → 1. Family duty and relationship building\n",
            "Categorising row 187... → 4. Cultural or generational norms\n",
            "Categorising row 190... → 2. Anti-transactional or moral objections\n",
            "Categorising row 193... → Anti-transactional or moral objections\n",
            "Categorising row 196... → 1. Family duty and relationship building\n",
            "Categorising row 197... → 2. Anti-transactional or moral objections\n",
            "Categorising row 198... → 1. Family duty and relationship building\n",
            "Categorising row 199... → 2. Anti-transactional or moral objections\n",
            "Categorising row 200... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 203... → 1. Family duty and relationship building\n",
            "Categorising row 205... → 4. Cultural or generational norms\n",
            "Categorising row 207... → 4. Cultural or generational norms\n",
            "Categorising row 212... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 214... → 2. Anti-transactional or moral objections\n",
            "Categorising row 220... → 1. Family duty and relationship building\n",
            "Categorising row 227... → 1. Family duty and relationship building\n",
            "Categorising row 230... → 4. Cultural or generational norms\n",
            "Categorising row 232... → 1. Family duty and relationship building\n",
            "Categorising row 233... → 4. Cultural or generational norms\n",
            "Categorising row 239... → 2. Anti-transactional or moral objections\n",
            "Categorising row 242... → 1. Family duty and relationship building\n",
            "Categorising row 251... → 2. Anti-transactional or moral objections\n",
            "Categorising row 267... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 268... → 2. Anti-transactional or moral objections\n",
            "Categorising row 272... → 1. Family duty and relationship building\n",
            "Categorising row 283... → 4. Cultural or generational norms\n",
            "Categorising row 286... → 2. Anti-transactional or moral objections\n",
            "Categorising row 292... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Categorising row 304... → 2. Anti-transactional or moral objections\n",
            "Categorising row 309... → 2. Anti-transactional or moral objections\n",
            "Categorising row 318... → 1. Family duty and relationship building\n",
            "Categorising row 329... → 4. Cultural or generational norms against payment\n",
            "Categorising row 330... → 1. Family duty and relationship building\n",
            "Categorising row 336... → 1. Family duty and relationship building\n",
            "Categorising row 341... → 1. Family duty and relationship building\n",
            "Categorising row 350... → 2. Anti-transactional or moral objections\n",
            "Categorising row 353... → 5. Payment is impractical, unnecessary, or creates complications\n",
            "Done. Saved as reddit_thread_with_all_reason_categories.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge"
      ],
      "metadata": {
        "id": "dF5HPfTTvkbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I had to merge my datasets as I'd output them as two different files lol."
      ],
      "metadata": {
        "id": "7sbdqEFGReYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_all = pd.read_csv(\"reddit_thread_with_all_reason_categories.csv\", dtype=str)\n",
        "df_for = pd.read_csv(\"reddit_thread_with_for_categories.csv\", dtype=str)\n",
        "\n",
        "\n",
        "if \"comment_id\" not in df_all.columns or \"comment_id\" not in df_for.columns:\n",
        "    raise ValueError(\"Both CSVs must contain comment_id for safe merging.\")\n",
        "\n",
        "df_for_subset = df_for[[\n",
        "    \"comment_id\",\n",
        "    \"for_reason_category\",\n",
        "    \"for_reason_explanation\"\n",
        "]]\n",
        "\n",
        "df_merged = df_all.merge(\n",
        "    df_for_subset,\n",
        "    on=\"comment_id\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "df_merged.to_csv(\"reddit_thread_with_all_reasons_complete.csv\", index=False)\n",
        "\n",
        "print(\"✓ Merged FOR reasons into the unified dataset.\")\n",
        "print(\"Saved as reddit_thread_with_all_reasons_complete.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKcxn9y-vluy",
        "outputId": "78155e05-3a5b-4ba5-c651-85af6df50d81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Merged FOR reasons into the unified dataset.\n",
            "Saved as reddit_thread_with_all_reasons_complete.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Value"
      ],
      "metadata": {
        "id": "ekRvuez7xAha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I actually ended up using this to filter the sheet in Excel and grab the most accurate values from comments manually. Money is really difficult to get clarification on, some were values for what people are paying for daycare, some were sarcastic values saying 'oh you should pay for 18 years of raising you' etc. This prompt just allowed me a general framework to filter by in Excel."
      ],
      "metadata": {
        "id": "Ai_A3yFMRlO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"reddit_thread_with_all_reasons_complete.csv\", dtype=str)\n",
        "\n",
        "target_rows = df[df[\"position\"].isin([\"for\", \"against\"])].copy()\n",
        "\n",
        "print(f\"Processing {len(target_rows)} comments with clear positions (for/against).\")\n",
        "\n",
        "MONEY_PROMPT = \"\"\"\n",
        "Determine whether the comment references money.\n",
        "\n",
        "Pick exactly ONE label:\n",
        "\n",
        "1. yes_explicit_amount = mentions a specific monetary value, e.g. $50, 80/day, 150 a week, $1200 a month.\n",
        "2. yes_money_words = mentions payment or cost without numbers. Words like pay, cost, charge, free, compensate.\n",
        "3. no = no monetary reference at all.\n",
        "\n",
        "OUTPUT FORMAT (exactly two lines):\n",
        "category: <one of the three labels>\n",
        "reason: <very short explanation>\n",
        "\n",
        "Comment: <<<COMMENT>>>\n",
        "\"\"\"\n",
        "\n",
        "def clean_comment(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    return text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\", \"ignore\").strip()\n",
        "\n",
        "def parse_two_line(raw):\n",
        "    cat = \"error\"\n",
        "    reason = raw.strip()\n",
        "\n",
        "    for line in raw.splitlines():\n",
        "        lower = line.lower().strip()\n",
        "        if lower.startswith(\"category:\"):\n",
        "            cat = line.split(\":\", 1)[1].strip()\n",
        "        elif lower.startswith(\"reason:\"):\n",
        "            reason = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "    return cat, reason\n",
        "\n",
        "def classify_money(comment, retries=1):\n",
        "    text = clean_comment(comment)\n",
        "    prompt = MONEY_PROMPT.replace(\"<<<COMMENT>>>\", text)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Respond strictly in two lines.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_completion_tokens=100,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        raw = response.choices[0].message.content\n",
        "        cat, rea = parse_two_line(raw)\n",
        "\n",
        "        if cat == \"error\" and retries > 0:\n",
        "            return classify_money(comment, retries - 1)\n",
        "\n",
        "        return cat, rea\n",
        "\n",
        "    except Exception as e:\n",
        "        if retries > 0:\n",
        "            return classify_money(comment, retries - 1)\n",
        "        return \"error\", str(e)\n",
        "\n",
        "\n",
        "df[\"mentions_money_value\"] = None\n",
        "df[\"mentions_money_reason\"] = None\n",
        "\n",
        "for idx, row in target_rows.iterrows():\n",
        "    comment = row[\"body\"]\n",
        "    print(f\"Row {idx}...\", end=\" \")\n",
        "\n",
        "    cat, rea = classify_money(comment)\n",
        "\n",
        "    df.at[idx, \"mentions_money_value\"] = cat\n",
        "    df.at[idx, \"mentions_money_reason\"] = rea\n",
        "\n",
        "    print(f\"→ {cat}\")\n",
        "\n",
        "df.to_csv(\"reddit_thread_with_money_detection.csv\", index=False)\n",
        "print(\"Done. Saved as reddit_thread_with_money_detection.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WahJh7lFxSb6",
        "outputId": "41d71a61-a60b-486f-d7f5-5536aee19a9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 153 comments with clear positions (for/against).\n",
            "Row 1... → no\n",
            "Row 2... → no\n",
            "Row 4... → yes_money_words\n",
            "Row 12... → yes_money_words\n",
            "Row 13... → yes_money_words\n",
            "Row 15... → yes_money_words\n",
            "Row 16... → no\n",
            "Row 17... → yes_money_words\n",
            "Row 19... → yes_money_words\n",
            "Row 21... → yes_money_words\n",
            "Row 25... → yes_money_words\n",
            "Row 26... → yes_money_words\n",
            "Row 28... → yes_money_words\n",
            "Row 29... → yes_money_words\n",
            "Row 30... → yes_money_words\n",
            "Row 31... → yes_money_words\n",
            "Row 32... → yes_money_words\n",
            "Row 34... → no\n",
            "Row 35... → no\n",
            "Row 38... → yes_money_words\n",
            "Row 39... → yes_money_words\n",
            "Row 41... → yes_money_words\n",
            "Row 45... → no\n",
            "Row 47... → yes_money_words\n",
            "Row 48... → yes_money_words\n",
            "Row 49... → yes_money_words\n",
            "Row 52... → yes_money_words\n",
            "Row 53... → yes_money_words\n",
            "Row 56... → yes_explicit_amount\n",
            "Row 57... → yes_money_words\n",
            "Row 58... → yes_money_words\n",
            "Row 59... → yes_money_words\n",
            "Row 62... → yes_money_words\n",
            "Row 63... → yes_money_words\n",
            "Row 65... → yes_money_words\n",
            "Row 66... → no\n",
            "Row 67... → yes_money_words\n",
            "Row 68... → yes_money_words\n",
            "Row 70... → yes_money_words\n",
            "Row 72... → yes_money_words\n",
            "Row 73... → yes_money_words\n",
            "Row 74... → yes_money_words\n",
            "Row 75... → no\n",
            "Row 76... → yes_money_words\n",
            "Row 79... → yes_money_words\n",
            "Row 80... → yes_money_words\n",
            "Row 81... → yes_money_words\n",
            "Row 82... → yes_money_words\n",
            "Row 83... → no\n",
            "Row 84... → yes_money_words\n",
            "Row 86... → yes_money_words\n",
            "Row 89... → yes_money_words\n",
            "Row 92... → no\n",
            "Row 93... → yes_money_words\n",
            "Row 94... → yes_money_words\n",
            "Row 95... → yes_money_words\n",
            "Row 97... → yes_money_words\n",
            "Row 98... → yes_money_words\n",
            "Row 101... → no\n",
            "Row 102... → no\n",
            "Row 103... → yes_money_words\n",
            "Row 108... → yes_money_words\n",
            "Row 110... → yes_money_words\n",
            "Row 118... → yes_money_words\n",
            "Row 123... → no\n",
            "Row 126... → yes_money_words\n",
            "Row 130... → no\n",
            "Row 133... → yes_money_words\n",
            "Row 134... → yes_money_words\n",
            "Row 136... → no\n",
            "Row 140... → yes_money_words\n",
            "Row 141... → yes_money_words\n",
            "Row 142... → yes_explicit_amount\n",
            "Row 143... → yes_money_words\n",
            "Row 144... → yes_money_words\n",
            "Row 150... → yes_money_words\n",
            "Row 155... → yes_money_words\n",
            "Row 156... → yes_money_words\n",
            "Row 157... → no\n",
            "Row 158... → yes_explicit_amount\n",
            "Row 165... → yes_money_words\n",
            "Row 166... → yes_explicit_amount\n",
            "Row 169... → yes_money_words\n",
            "Row 170... → no\n",
            "Row 171... → no\n",
            "Row 172... → yes_money_words\n",
            "Row 173... → yes_money_words\n",
            "Row 174... → yes_money_words\n",
            "Row 177... → yes_money_words\n",
            "Row 178... → yes_money_words\n",
            "Row 180... → no\n",
            "Row 181... → no\n",
            "Row 184... → yes_money_words\n",
            "Row 185... → yes_money_words\n",
            "Row 187... → yes_money_words\n",
            "Row 190... → yes_money_words\n",
            "Row 191... → yes_explicit_amount\n",
            "Row 193... → yes_money_words\n",
            "Row 194... → no\n",
            "Row 196... → yes_money_words\n",
            "Row 197... → yes_money_words\n",
            "Row 198... → yes_money_words\n",
            "Row 199... → yes_money_words\n",
            "Row 200... → yes_money_words\n",
            "Row 201... → yes_money_words\n",
            "Row 202... → yes_money_words\n",
            "Row 203... → no\n",
            "Row 205... → yes_money_words\n",
            "Row 207... → yes_money_words\n",
            "Row 209... → yes_money_words\n",
            "Row 212... → no\n",
            "Row 214... → no\n",
            "Row 217... → yes_money_words\n",
            "Row 218... → yes_money_words\n",
            "Row 220... → no\n",
            "Row 224... → no\n",
            "Row 226... → yes_money_words\n",
            "Row 227... → no\n",
            "Row 230... → yes_money_words\n",
            "Row 232... → yes_money_words\n",
            "Row 233... → yes_money_words\n",
            "Row 239... → no\n",
            "Row 240... → yes_money_words\n",
            "Row 242... → no\n",
            "Row 251... → yes_money_words\n",
            "Row 253... → yes_explicit_amount\n",
            "Row 254... → yes_explicit_amount\n",
            "Row 256... → yes_money_words\n",
            "Row 257... → yes_explicit_amount\n",
            "Row 260... → no\n",
            "Row 265... → yes_money_words\n",
            "Row 267... → no\n",
            "Row 268... → yes_explicit_amount\n",
            "Row 272... → yes_money_words\n",
            "Row 275... → yes_money_words\n",
            "Row 281... → yes_money_words\n",
            "Row 282... → yes_money_words\n",
            "Row 283... → yes_money_words\n",
            "Row 285... → no\n",
            "Row 286... → yes_money_words\n",
            "Row 292... → yes_money_words\n",
            "Row 304... → no\n",
            "Row 309... → no\n",
            "Row 318... → no\n",
            "Row 328... → yes_money_words\n",
            "Row 329... → yes_money_words\n",
            "Row 330... → yes_money_words\n",
            "Row 331... → no\n",
            "Row 332... → no\n",
            "Row 336... → no\n",
            "Row 341... → no\n",
            "Row 350... → no\n",
            "Row 353... → no\n",
            "Done. Saved as reddit_thread_with_money_detection.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "gBiXpPFfy_QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was the analysis I did of the final CSV with all of the For, Against, Reasons columns. It's very basic, and I'm not convinced there is enough there to provide a solid story, however I think it aligns well with Clea's expectations of this dataset.\n",
        "\n",
        "I then manually looked at the monetary values as discussed above."
      ],
      "metadata": {
        "id": "2ltmfhKpSLbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"reddit_thread_with_money_detection.csv\", dtype=str)\n",
        "df = df.fillna(\"\")\n",
        "\n",
        "\n",
        "try:\n",
        "    df[\"score\"] = df[\"score\"].astype(int)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "relevant_df = df[df[\"relevance\"] == \"relevant\"]\n",
        "total_relevant = len(relevant_df)\n",
        "\n",
        "\n",
        "position_counts = relevant_df[\"position\"].value_counts()\n",
        "position_pct = (position_counts / total_relevant * 100).round(1)\n",
        "\n",
        "position_table = pd.DataFrame({\n",
        "    \"count\": position_counts,\n",
        "    \"percent\": position_pct\n",
        "})\n",
        "\n",
        "\n",
        "# FOR\n",
        "for_df = relevant_df[relevant_df[\"position\"] == \"for\"]\n",
        "for_total = len(for_df)\n",
        "\n",
        "for_reason_counts = for_df[\"for_reason_category\"].value_counts()\n",
        "for_reason_pct = (for_reason_counts / for_total * 100).round(1)\n",
        "\n",
        "for_reason_table = pd.DataFrame({\n",
        "    \"count\": for_reason_counts,\n",
        "    \"percent\": for_reason_pct\n",
        "})\n",
        "\n",
        "# AGAINST\n",
        "against_df = relevant_df[relevant_df[\"position\"] == \"against\"]\n",
        "against_total = len(against_df)\n",
        "\n",
        "against_reason_counts = against_df[\"against_reason_category\"].value_counts()\n",
        "against_reason_pct = (against_reason_counts / against_total * 100).round(1)\n",
        "\n",
        "against_reason_table = pd.DataFrame({\n",
        "    \"count\": against_reason_counts,\n",
        "    \"percent\": against_reason_pct\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "top_comments = relevant_df.sort_values(\"score\", ascending=False).head(10)[[\n",
        "    \"comment_id\", \"body\", \"position\", \"score\", \"mentions_money_value\"\n",
        "]]\n",
        "\n",
        "avg_score_pos = relevant_df.groupby(\"position\")[\"score\"].mean().round(1)\n",
        "\n",
        "\n",
        "print(\"\\n=== POSITION BREAKDOWN (relevant comments only) ===\")\n",
        "print(position_table, \"\\n\")\n",
        "\n",
        "print(\"=== FOR-REASON CATEGORIES ===\")\n",
        "print(for_reason_table, \"\\n\")\n",
        "\n",
        "print(\"=== AGAINST-REASON CATEGORIES ===\")\n",
        "print(against_reason_table, \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqLjysTozBxy",
        "outputId": "87b43ccc-1575-4757-d0c0-89c23a7dd605"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== POSITION BREAKDOWN (relevant comments only) ===\n",
            "          count  percent\n",
            "position                \n",
            "neutral     113     42.5\n",
            "against     111     41.7\n",
            "for          42     15.8 \n",
            "\n",
            "=== FOR-REASON CATEGORIES ===\n",
            "                                              count  percent\n",
            "for_reason_category                                         \n",
            "3. Fairness and avoiding exploitation             8     19.0\n",
            "Compensation for labour and effort                7     16.7\n",
            "1. Compensation for labour and effort             7     16.7\n",
            "4. Covering expenses and out of pocket costs      6     14.3\n",
            "2. Preventing financial harm or lost income       5     11.9\n",
            "5. Systemic or policy reasons                     5     11.9\n",
            "Preventing financial harm or lost income          3      7.1\n",
            "Fairness and avoiding exploitation                1      2.4 \n",
            "\n",
            "=== AGAINST-REASON CATEGORIES ===\n",
            "                                                    count  percent\n",
            "against_reason_category                                           \n",
            "1. Family duty and relationship building               40     36.0\n",
            "4. Cultural or generational norms                      26     23.4\n",
            "2. Anti-transactional or moral objections              24     21.6\n",
            "5. Payment is impractical, unnecessary, or crea...     12     10.8\n",
            "3. Prefer professional childcare instead                5      4.5\n",
            "4. Cultural or generational norms against payment       2      1.8\n",
            "Family duty and relationship building                   1      0.9\n",
            "Anti-transactional or moral objections                  1      0.9 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqDaF9nmSpJC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}